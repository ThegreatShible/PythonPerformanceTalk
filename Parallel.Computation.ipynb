{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Intro to Faster Computation\n",
    "### or some insights into speeding up your Python code\n",
    "Pavel SORIANO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is this talk about?\n",
    "\n",
    "* Get an overview on how to make code run faster with a focus on Python.\n",
    "    * Making use of our language-of-choice inherent features\n",
    "    * Passing to lower-level speedups\n",
    "    * Using parallel computation\n",
    "\n",
    "### Why?\n",
    "* We have the technology!\n",
    "* Large datasets\n",
    "* Costly algorithms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Talk Outline\n",
    "\n",
    "1. Overview of a machine learning task as use case\n",
    "2. Some guidelines to (better) programming Python \n",
    "3. Some solutions to add C/C++ code inside our Python code\n",
    "4. Parallel programming in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " ## Data Science Reminder\n",
    "* __Build software__ able to predict and describe\n",
    "* Using __Machine Learning__ (ML) techniques  \n",
    "\n",
    "* Typical approaches:\n",
    "    * __Supervised Learning__: Regression, Classification\n",
    "    * __Unsupervised Learning__: Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parametric vs. Non-parametric\n",
    "* Parametric\n",
    "    * Often faster to use\n",
    "    * Make assumptions about the nature of the data distributions\n",
    "* Non-parametric\n",
    "    * More flexible,\n",
    "    * Often computationally intractable for large datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## k - Nearest Neighbors (kNN)\n",
    "* Simple non-parametric classifier\n",
    "* Instance-based (no need to generalize)\n",
    "\n",
    "* Given a labelled dataset $D$,  a new data point $x$ and an integer value $k$,  the main three steps of kNN are:\n",
    "    1. Measure the similarity (or distance) between $x$ and each point in $D$.\n",
    "    2. Sort the points according to the calculated similarity\n",
    "    3. Assign $x$ the majority class found in the top $k$ points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Task Definition\n",
    "* We define a syntetic dataset with 750 samples, 20 features and 2 classes.\n",
    "* The objective is to classify these samples using a supervised machine learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "%load_ext Cython\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "X, Y = datasets.make_classification(n_samples=750, n_features=20,\n",
    "                                    n_informative=2, n_redundant=2, n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 20)\n",
      "[[ 1.75761714e-01 -7.34399585e-01  4.23749769e-01 -1.57847620e+00\n",
      "  -2.40050190e+00 -1.05980771e-02  8.93842289e-01  2.21004088e+00\n",
      "   8.58749273e-01 -2.57273607e-01 -1.59658890e+00 -1.07569127e+00\n",
      "  -8.17482141e-01  2.51642658e-01  6.29761703e-01 -5.32027925e-01\n",
      "  -1.13744286e+00 -5.97860959e-01 -1.26669464e-01 -1.26635441e+00]\n",
      " [-2.39234675e+00 -1.41695243e+00  3.51350023e-01  2.71789856e+00\n",
      "  -3.21624738e-02 -1.28219452e+00  6.16381907e-01 -1.00570238e+00\n",
      "   1.31146338e+00  9.92597089e-01 -1.22039655e-01 -1.64125494e+00\n",
      "  -5.94194711e-01 -2.19571095e+00 -3.56528357e-01  1.49355762e+00\n",
      "  -3.34339435e-03  1.07060287e+00 -1.60216243e+00  1.32087383e+00]\n",
      " [-2.41161698e+00  1.30430122e+00  8.92254726e-01 -2.23926390e-01\n",
      "   6.44256672e-01 -1.25329229e+00  5.83741510e-01  4.68005940e-01\n",
      "   2.80521500e-01  1.61384001e+00 -8.61480666e-01  2.84676172e+00\n",
      "   3.63659505e-01 -2.24721034e+00 -1.04759837e+00  9.76176006e-02\n",
      "   5.55006873e-01 -1.39963660e+00 -1.52358774e+00  1.46600520e+00]\n",
      " [-2.26125955e+00 -1.17926622e+00 -9.63879731e-01  2.12216798e-01\n",
      "   1.73339123e-02 -1.31632663e+00 -3.44211469e+00 -1.27825799e-01\n",
      "   4.20798597e-01  1.56789540e-02 -5.59698856e-01  7.12312218e-01\n",
      "   5.46338836e-01 -1.98542385e+00 -2.50699420e-01 -1.28965337e+00\n",
      "  -8.35989953e-01  2.84084070e-01 -1.75779550e+00 -8.11620242e-01]\n",
      " [-1.30918379e+00  1.99861588e+00  2.78584259e-01  2.06345793e-02\n",
      "   8.35516591e-01 -7.76951260e-01 -9.10683317e-01 -1.80299074e-01\n",
      "  -4.15871485e-01  5.51727166e-02 -6.66192747e-01  1.80503779e-01\n",
      "   3.35388364e-01 -1.13668775e+00  1.56809737e+00 -4.45088860e-01\n",
      "   1.30685545e+00  2.87579345e-01 -1.05232060e+00 -4.13552124e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print\n",
    "print(X[:5,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750,)\n",
      "[0 0 0 0 0 1 1 1 0 0 1 1 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 0 1 1\n",
      " 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 0 0 1 1\n",
      " 1 0 0 0 0 1 1 1 0 1 1 1 1 0 1 1 0 0 0 0 1 0 1 0 1 1 0 0 0 1 1 1 1 1 0 0 1\n",
      " 1 0 0 0 0 1 0 1 1 0 0 0 1 0 0 1 1 0 0 0 0 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 1\n",
      " 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 0 0 1 1 1 1 1 1 0 0 0 0 0 1 1 1 0 0 0 1 1 0\n",
      " 1 0 0 0 0 1 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 0 0 1 1 0 0 0 1 0 0 1 0 1 0 1 1\n",
      " 0 0 1 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1\n",
      " 0 1 1 1 1 0 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0 1 0 1 1 0 1\n",
      " 1 0 0 0 1 0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 1 0 0 1 1 0 1\n",
      " 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1\n",
      " 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 1 1 0 1 0 1 1 0\n",
      " 0 1 0 1 0 1 1 1 1 0 0 0 1 1 0 1 0 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0 1 0 0\n",
      " 1 0 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 1 1 1 0 1 1 1 1 0 1 0 1 0 0\n",
      " 0 0 1 1 0 0 1 1 0 0 0 1 1 1 1 0 0 0 1 0 1 1 0 0 0 0 1 1 0 0 1 0 0 1 1 0 1\n",
      " 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 0 0 0\n",
      " 1 1 1 1 0 1 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1\n",
      " 1 1 1 0 0 0 1 1 0 1 1 0 0 0 1 1 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 1\n",
      " 1 0 0 0 0 1 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)\n",
    "print\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# First step\n",
    "Given a labelled dataset $D$,  a new data point $p$ and an integer value $k$,  the main three steps of kNN are:\n",
    "1. __Measure the Euclidean distance between $p$ and each point in $q \\in D$__\n",
    "\n",
    "    $$d(p,q) = \\sqrt{\\sum_{i=1}^{n}(p_i-q_i)^2}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.454959754738583\n",
      "8.454959754738583\n"
     ]
    }
   ],
   "source": [
    "def euclidean_distance(p,q):\n",
    "    euclidean_dist = 0\n",
    "    for i in range(len(p)):\n",
    "        euclidean_dist += (p[i] - q[i])**2\n",
    "    return np.sqrt(euclidean_dist)\n",
    "\n",
    "print(euclidean_distance(X[0,], X[1,]))\n",
    "print(np.linalg.norm(X[0,] - X[1,]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Second step\n",
    "\n",
    "1. Measure the Euclidean distance between $x$ and each point in $D$\n",
    "2. __Sort the points according to the calculated similarity__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, 0), (3, 1), (2, 2), (1, 3), (0, 4)]\n"
     ]
    }
   ],
   "source": [
    "def sort_array(array):\n",
    "    # Return the sorted array and its indices as a list of tuples : [(index1, value1), (index2,value2)]\n",
    "    indexed_array = dict(zip(range(len(array)), array))\n",
    "    return sorted(indexed_array.items(), key=lambda x:x[1])\n",
    "    \n",
    "# test \n",
    "print(sort_array([4,3,2,1,0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Third step\n",
    "\n",
    "1. Measure the similarity (or distance) between $x$ and each point in $D$.\n",
    "2. Sort the points according to the calculated similarity\n",
    "3. __Assign $x$ the majority class found in the top $k$ points__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def assign_class(k, ordered_distances, Y):\n",
    "    from collections import Counter\n",
    "\n",
    "    closest_ids = [s[0] for s in ordered_distances[:k]]\n",
    "    closest_labels = Y[closest_ids]\n",
    "    chosen_label = Counter(closest_labels).most_common()[0][0]\n",
    "    return chosen_label\n",
    "#test\n",
    "# assign_class(3, [(3, 1), (2, 2), (1, 3), (0, 4)], np.array([1,2,2,2,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Putting it all together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def kNN(X, Y, k, test_points):\n",
    "    test_classes = []\n",
    "    for p in test_points:\n",
    "        distances = []\n",
    "        for i in range(X.shape[0]):\n",
    "            if not np.array_equal(p, X[i, ]):\n",
    "                distances.append(euclidean_distance(X[i, ], p))\n",
    "        ordered_distances = sort_array(distances)\n",
    "        chosen_label = assign_class(k, ordered_distances, Y)\n",
    "        test_classes.append(chosen_label)\n",
    "    return test_classes\n",
    "\n",
    "# print kNN(X, Y, 3, X[101:120,])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8377777777777777\n"
     ]
    }
   ],
   "source": [
    "# Test its accuracy. Just because why not\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.6)\n",
    "Y_hat = kNN(X_train, Y_train, 3, X_test)\n",
    "\n",
    "print(accuracy_score(Y_test, Y_hat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Measure to improve: Profiling\n",
    "* Very important first step before improving our code\n",
    "* Find these hotspots in the code\n",
    "    * What is slow? \n",
    "    * What is using too much memory? \n",
    "    * Maybe too much network or disk I/O?\n",
    "* We want to do the least amount of work to get the biggest practical performance gain. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Profiling\n",
    "### timeit module\n",
    "* Coarse profiling\n",
    "* Runs our code in a loop, multiple times.\n",
    "* Returns the best averaged result (in term of time) of all the loop repetitions\n",
    "* We want the best result because the slower results may be due to the computer busy with other things\n",
    "* By default it runs 10 loops (swith _n_) with 3 repetitions (switch _r_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Always profile before optimizing. You could spend time optimizing a function that is in fact not taking that much time as others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.39 s ± 109 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 3 -r 3 kNN(X_train, Y_train, 5, X_test)\n",
    "# In pure Python\n",
    "# python -m timeit -n 3 -r 3 \"kNN(X_train, Y_train, 3, X_test)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Profiling\n",
    "### cProfile module\n",
    "* Built-in profiling tool\n",
    "* Hooks into CPython virtual machine\n",
    "* We can get a high-level overview of the time spent in our code\n",
    "* Function-based profiling\n",
    "* Add some overhead making code run slower\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "*** Profile stats marshalled to file 'program.prof'. \n"
     ]
    }
   ],
   "source": [
    "%prun -s cumulative -D program.prof kNN(X_train, Y_train, 5, X_test)\n",
    "# In pure Python\n",
    "# python -m cProfile -s cumulative kNN.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![title](img/cProfile_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* The entry point of our kNN function is indicated in line 2. It takes a total of 2.7 seconds. As expected, this function is only called once, shown in ncalls.\n",
    "\n",
    "* Inside kNN, euclidean_distance takes 1.598 seconds to compute and it is called 135,000 times, which makes sense because we have a 750 points dataset, we split it into 450 training (40%) and 300 testing (60%). So 450x300 = 135k\n",
    "\n",
    "* In second place of slowness, we have the array_equal call, taking 0.85 seconds. Actually the next four lines (all, _all, reduce, asarray) are part of this call. \n",
    "\n",
    "* Way below we find our sort_array function, which seems to be not very slow and in last place we have assign_class, with 0.20 cumtime\n",
    "\n",
    "* So, with this knowledge we can focus in the first two slow parts: euclidean_distance and the array_equal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* cumtime is the time spent in the function/method including the time spent in the functions/methods that it calls\n",
    "* tottime is the time spent in the function/method excluding the time spent in the functions/methods that it calls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Profiling\n",
    "### SnakeViz\n",
    "Browser based grpahical viewer of cProfile's output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snakeviz web server started on 127.0.0.1:8080; enter Ctrl-C to exit\n",
      "http://127.0.0.1:8080/snakeviz/%2Fhome%2Fpavel%2Fcode%2FPythonPerformanceTalk%2Fprogram.prof\n",
      "^C\n",
      "\n",
      "Bye!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#pip install snakeviz\n",
    "!snakeviz program.prof "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Profiling\n",
    "### line_profiler module\n",
    "* Profiles individual functions on a line-by-line basis. \n",
    "* After analyzing the code with cProfile, we can go deeper with line_profiler\n",
    "* Very important tool for Python CPU-based profling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%lprun -f kNN -f euclidean_distance -f sort_array -f assign_class kNN(X_train, Y_train, 5, X_test)\n",
    "# In Python (needs decorators):\n",
    "# kernprof.py -l -v my_script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![title](img/line_prof0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![title](img/line_prof1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "dynamic lookup at every loop. Compiling and type specialization would improve this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![title](img/line_profiler2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Optimizing Cycle\n",
    "\n",
    "1. Create a real use case benchmark. A big enough chunk of data that does not take forever to compute\n",
    "2. Run a profiler (high-level: cProfile, in-detail: line_profiler)\n",
    "3. Look for hotspots. If one or two functions take more than (roughly) 60% of the time, there is hope.\n",
    "4. Apply optimization\n",
    "5. Re-run benchmark (luckily you will see improvements)\n",
    "6. Optional but should not be optional: Test that your algorithm is still correct after modifications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Some faster Python guidelines\n",
    "\n",
    "* While using matrices, or vectors, do not deal with items line-by-line or point-by-point (try to avoid `for` loops)\n",
    "* If possible, use sets, and by extension, dictionaries to get fast access to data\n",
    "* Still, if your data has already a defined order, stay with lists and/or tuples\n",
    "* Pre-allocate your `numpy` arrays\n",
    "* If your data is static, it is better to use tuples\n",
    "* Take advantage of generators. They use less memory and may avoid costly operations while dealing only with punctual values of interest.\n",
    "* Try to avoid conditions inside _for_ loops\n",
    "* Take advantage of elementary built-in functions (`sorted`, `min`, `max`) and look for higher-level well-known solutions to your problems (`numpy`, `scikit-learn`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def i_hate_broadcasting():\n",
    "    a = np.array([1.0, 2.0, 3.0])\n",
    "    b = np.array([2.0, 2.0, 2.0])\n",
    "    a * b\n",
    "\n",
    "def i_love_broadcasting():\n",
    "    a = np.array([1.0, 2.0, 3.0])\n",
    "    b = 2.0\n",
    "    a * b\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Improving the code somehow\n",
    "\n",
    "* Remove the _if_ condition from the `for` loop. Check for distance greater than zero in a list comprehension\n",
    "* Eliminate one `for` loop by using Numpy broadcasting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 2.1 s per loop\n"
     ]
    }
   ],
   "source": [
    "# Recall the original time duration\n",
    "%timeit kNN(X_train, Y_train, 5, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def assign_class2(k, ordered_distances, Y):\n",
    "    \"\"\"\n",
    "    We check in the list comprehension that the distance is greater than zero\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "\n",
    "    closest_ids = [s[0] for s in ordered_distances[:k] if s[1] > 0]\n",
    "    closest_labels = Y[closest_ids]\n",
    "    chosen_label = Counter(closest_labels).most_common()[0][0]\n",
    "    return chosen_label\n",
    "\n",
    "def kNN2(X, Y, k, test_points):\n",
    "    \"\"\"\n",
    "    We remove the if condition at each iteration!\n",
    "    \"\"\"\n",
    "    test_classes = []\n",
    "    for p in test_points:\n",
    "        distances = []\n",
    "        for i in range(X.shape[0]):\n",
    "            distances.append(euclidean_distance(X[i, ], p))\n",
    "        ordered_distances = sort_array(distances)\n",
    "        chosen_label = assign_class2(k, ordered_distances, Y)\n",
    "        test_classes.append(chosen_label)\n",
    "    return test_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 1.47 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit kNN2(X_train, Y_train, 5, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def kNN3(X, Y, k, test_points):\n",
    "    \"\"\"\n",
    "    We eliminate one for loop by using broadcasting and calculating the distance between each dataset\n",
    "    point and the test point.\n",
    "    \"\"\"\n",
    "    test_classes = []\n",
    "    for p in test_points:\n",
    "        distances = np.sqrt(((X[:, np.newaxis] - p) ** 2).sum(axis=-1))\n",
    "        ordered_distances = sort_array(distances)\n",
    "        chosen_label = assign_class2(k, ordered_distances, Y)\n",
    "        test_classes.append(chosen_label)\n",
    "    return test_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 502 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit kNN3(X_train, Y_train, 5, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stop Here!\n",
    "* From a code-maintenance point of view, it is wise to stop here\n",
    "* We should appreaciate the quick wins and consider the diminishing returns with the extra effort involved\n",
    "* In 3 months (or 3 days), our smart code snippets will be hard to interpret even for ourselves\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Enter the Machine Code\n",
    "* Python is dinamically typed, so at each moment the virtual machine has a difficult time optimizing the machine code as it does not know what is the type of data used in the program\n",
    "* A recurrent approach in most of the most important machine learning libraries.\n",
    "* Python is used as a \"glue\" (front-end) while the computations are done in C or Fortran\n",
    "* Once we are using solid algorithms, data structures, efficient code, we may go on with compiling code\n",
    "* We compile the slowest parts of our code in machine code (using C/LLVM) within Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Enter the Machine Code\n",
    "\n",
    "* Works well when you have a lot of loops (because you can't avoid them)\n",
    "* Reach close-to-C performance\n",
    "* Not very useful for I/O operations, string manipulation and calls to external modules\n",
    "* Adds a considerable layer of complexity to your code\n",
    "* Very active area. Changes/new developments appear constantly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Tools\n",
    "\n",
    "|   Name  | Compiler | Numpy compatible? |\n",
    "|:-------:|:--------:|:-----------------:|\n",
    "|  Cython |    AOT   |        yes        |\n",
    "|  Numba  |    JIT   |        some        |\n",
    "| Pythran |    AOT   |        yes        |\n",
    "|   PyPy  |    JIT   |         no        |\n",
    "\n",
    "* Ahead Of Time (AOT) compiler\n",
    "    * Creates a static library which is called every time you use the compiled code\n",
    "    * Scikit-learn, scipy, and others are installed with these static libraries \n",
    "* Just In Time (JIT) compiler\n",
    "    * Most of the times all it requires is a decorator and your code is compiled on the fly at execution\n",
    "    * It may slowdown considerably during the startup of your program as it is compiling the code to be used during execution. Later references to compiled code should run faster.\n",
    "* Trade-off between speed vs simplicity. Although JIT solutions seem to be faster or at least as fast as AOT compilers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cython\n",
    "* Cython is a programming language for writing C extensions in Python\n",
    "* Adds type annotations to Python allowing fast compiled code\n",
    "* Cython is a superset of Python, a kind of hybrid between Python and C\n",
    "* Simple to start using it but gets complex as more requirements are needed\n",
    "* Supports OpenMP allowing (as the name indicates) multi-processes to run in parallel\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/share/anaconda/lib/python2.7/site-packages/IPython/utils/path.py:264: UserWarning: get_ipython_cache_dir has moved to the IPython.paths module\n",
      "  warn(\"get_ipython_cache_dir has moved to the IPython.paths module\")\n"
     ]
    }
   ],
   "source": [
    "%%cython\n",
    "cimport cython\n",
    "cimport numpy as np\n",
    "from libc.math cimport sqrt\n",
    "\n",
    "def assign_class4(k, ordered_distances, Y):\n",
    "    \"\"\"\n",
    "    We check in the list comprehension that the distance is greater than zero\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "\n",
    "    closest_ids = [s[0] for s in ordered_distances[:k] if s[1] > 0]\n",
    "    closest_labels = Y[closest_ids]\n",
    "    chosen_label = Counter(closest_labels).most_common()[0][0]\n",
    "    return chosen_label\n",
    "\n",
    "def sort_array4(array):\n",
    "    indexed_array = dict(zip(range(len(array)), array))\n",
    "    return sorted(indexed_array.items(), key=lambda x:x[1])\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def euclidean_distance4(np.ndarray[double, ndim=1] p, np.ndarray[double, ndim=1] q):\n",
    "    cdef double euclidean_dist = 0\n",
    "    cdef unsigned int i\n",
    "    for i in range(p.shape[0]):\n",
    "        euclidean_dist += (p[i] - q[i])**2\n",
    "    return sqrt(euclidean_dist)\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "\n",
    "def kNN4(X, Y, k, test_points):\n",
    "    test_classes = []\n",
    "    for p in test_points:\n",
    "        distances = []\n",
    "        for i in range(X.shape[0]):\n",
    "            distances.append(euclidean_distance4(X[i, ], p))\n",
    "        ordered_distances = sort_array4(distances)\n",
    "        chosen_label = assign_class4(k, ordered_distances, Y)\n",
    "        test_classes.append(chosen_label)\n",
    "    return test_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 194 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit kNN4(X_train, Y_train, 5, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Numba\n",
    "* JIT compiler that transforms Python into optimized machine code using the LLVM Intermediate Representation \n",
    "* Does not use g++ or gcc as Cython.\n",
    "* It only needs some decorators to work\n",
    "* Also allows parallel execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "\n",
    "@jit\n",
    "def euclidean_distance5(p,q):\n",
    "    euclidean_dist = 0\n",
    "    for i in range(len(p)):\n",
    "        euclidean_dist += (p[i] - q[i])**2\n",
    "    return np.sqrt(euclidean_dist)\n",
    "\n",
    "def kNN5(X, Y, k, test_points):\n",
    "    \"\"\"\n",
    "    We use numba!\n",
    "    \"\"\"\n",
    "    test_classes = []\n",
    "    for p in test_points:\n",
    "        distances = []\n",
    "        for i in range(X.shape[0]):\n",
    "            distances.append(euclidean_distance5(X[i, ], p))\n",
    "        ordered_distances = sort_array(distances)\n",
    "        chosen_label = assign_class2(k, ordered_distances, Y)\n",
    "        test_classes.append(chosen_label)\n",
    "    return test_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 165 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit kNN5(X_train, Y_train, 5, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pythran\n",
    "* Subset of the Python language, with a focus on scientific computing\n",
    "* Specifically oriented towards scientific computing\n",
    "* Allows parallel execution\n",
    "* No need to \"dumb\" down your code. You can use Numpy oriented functions directly\n",
    "* Made in France"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Not enough? Larger dataset? Let's parallelize\n",
    "* We have multi-core computers everywhere. We should be making them work for us (sometimes)\n",
    "* Best case scenario: $n$ times speedup, where $n$ is your number of cores. Still, some overhead is created and it surely will slowdown\n",
    "* Python has OS-native threads (real deal threads). Still, they are bound bu the Global Interpreter Lock (GIL)\n",
    "* This means that only one thread may interact with Python objects at a time\n",
    "* The GIL is avoided usually by:\n",
    "    * Using processes: we run Python interpreters in parallel, each running in a private memory space with its own GIL and running code in series\n",
    "    * By releasing the GIL with low-level solutions (Cython, Numba, etc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Not enough? Larger dataset? Let's parallelize\n",
    "### Some considerations\n",
    "* Libraries used should be thread-safe to avoid hard-to-debug problems\n",
    "* Amdahl's Law: Be aware that most of the execution time is taken by serial operations. If only a small part of the code can be parallelized, then it is of little importance how many processors you use. It won't run a lot faster.\n",
    "* Hyperthreading = ~30% of a real extra core\n",
    "* Much easier to work on \\*nix-based systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Type of parallel problems\n",
    "* Fine coarsed: tasks must communicate many times per second\n",
    "* Grain coarsed: they do not communicate many times per second\n",
    "* Embarassingly parallel: no communication (or very rarely) between tasks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multiprocessing \n",
    "* Python module that allows us to spawn processes\n",
    "* Effectively side-steps the Global Interpreter Lock by using subprocesses instead of threads\n",
    "* It pickles parameters and functions and pass them around. Try not to pass a lot of data... \n",
    "* Keep the functions as simple as possible\n",
    "\n",
    "## Joblib\n",
    "* Lightweight pipelining in Python\n",
    "* Provides a helper class to write parallel for loops using multiprocessing\n",
    "* Transparent and fast disk-caching of output values\n",
    "* The vision is to provide tools to easily achieve better performance and reproducibility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multiprocessing Example (with a much larger dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "X, Y = datasets.make_classification(n_samples=5000, n_features=20,\n",
    "                                    n_informative=2, n_redundant=2, n_classes=2)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.6)\n",
    "\n",
    "X_g = X_train\n",
    "Y_g = Y_train\n",
    "k_g = 5\n",
    "\n",
    "\n",
    "def single_distance(p):\n",
    "    distances = np.sqrt(((X_g[:, np.newaxis] - p) ** 2).sum(axis=-1))\n",
    "    ordered_distances = sort_array(distances)\n",
    "    chosen_label = assign_class2(k_g, ordered_distances, Y_g)\n",
    "    return chosen_label\n",
    "\n",
    "\n",
    "def kNN6(test_points):\n",
    "        \n",
    "    import multiprocessing\n",
    "    \"\"\"\n",
    "    We try the parallel version!\n",
    "    \"\"\"\n",
    "    pool = multiprocessing.Pool(processes = 4)\n",
    "    test_classes = pool.map(single_distance, test_points)\n",
    "    return test_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 10 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit kNN6(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Now let's try the fastest single core version with Numba (same large dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-203ec301538d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'timeit kNN5(X_train, Y_train, 5, X_test)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/share/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mmagic\u001b[1;34m(self, arg_s)\u001b[0m\n\u001b[0;32m   2334\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2335\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2336\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2338\u001b[0m     \u001b[1;31m#-------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/share/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line)\u001b[0m\n\u001b[0;32m   2255\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2256\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2257\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2258\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/share/anaconda/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, line, cell)\u001b[0m\n",
      "\u001b[1;32m/usr/share/anaconda/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/share/anaconda/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, line, cell)\u001b[0m\n\u001b[0;32m   1040\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m                 \u001b[0mnumber\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m         \u001b[0mall_runs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1043\u001b[0m         \u001b[0mbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mquiet\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/share/anaconda/lib/python2.7/timeit.pyc\u001b[0m in \u001b[0;36mrepeat\u001b[1;34m(self, repeat, number)\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m             \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/share/anaconda/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, number)\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             \u001b[0mtiming\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[1;34m(_it, _timer)\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-7c038aa2fe4f>\u001b[0m in \u001b[0;36mkNN5\u001b[1;34m(X, Y, k, test_points)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mdistances\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meuclidean_distance5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mordered_distances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msort_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mchosen_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0massign_class2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mordered_distances\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%timeit kNN5(X_train, Y_train, 5, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallelizing by releasing the GIL\n",
    "* If we use Cython it is as easy as calling the appropriate commands with _nogil_ and _prange_\n",
    "![title](img/nogil.png)\n",
    "* While using Numba \n",
    "![title](img/prange_numba.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Me, parallelizing ... in Java ¯\\\\_(ツ)_/¯\n",
    "Show my use case here. Not data science per se but still useful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Other promising tool: Dask\n",
    ">Dask enables parallel computing through task scheduling and blocked algorithms. This allows developers to write complex parallel algorithms and execute them in parallel either on a modern multi-core machine or on a distributed cluster.\n",
    "![title](img/dask.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Requirements\n",
    "\n",
    "* Anaconda \n",
    "* Ipython?\n",
    "* PyCharm?\n",
    "* Unix system (easier parallelization with processes)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "* Premature optimization is the root of all evil. Still, no excuses for lazy, slow code\n",
    "* Still, do not waste time optimizing something that is not optimizable. Better to look for other algorithms/logic\n",
    "* Unit testing should be part of our experiments. We may introduce errors to our functions in our quest for speed\n",
    "* Keeping it readable is the top priority, in 2 weeks you won't remember what your clever self from the past did\n",
    "* Don't get addicted to it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "* High Performance Python. Micha Gorelick and Ian Ozvald\n",
    "* Python for Data Analysis. Wes McKinney\n",
    "* Course from V. Miele http://pbil.univ-lyon1.fr/members/miele/tutoriel/\n",
    "* Travis Oliphant blog http://technicaldiscovery.blogspot.fr/2011/06/speeding-up-python-numpy-cython-and.html\n",
    "* Jake VanderPlas blog https://jakevdp.github.io/blog/2013/06/15/numba-vs-cython-take-2/\n",
    "* Scipy performance tips http://scipy.github.io/old-wiki/pages/PerformanceTips\n",
    "* Using Python for performance computing http://scipy.github.io/old-wiki/pages/PerformancePython\n",
    "* Scikit-learn performance tips http://scikit-learn.org/stable/developers/performance.html\n",
    "* Machine Learning:  A Probabilistic Perspective. Kevin P. Murphy\n",
    "* A Course in Machine Learning. Hal Daume III\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let us get to work with XGBoost-Dask"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
